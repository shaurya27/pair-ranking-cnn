{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import *\n",
    "from constant import *\n",
    "from load_data import *\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD_SIZE = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaurya/anaconda2/lib/python2.7/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = Model(WORD_SIZE,WORD_DIM,NUM_FILTERS,FILTER_SIZES,DROPOUT,HIDDEN_SIZE,pretrained_word_embeds)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "criterion = torch.nn.NLLLoss(size_average=False)\n",
    "bce_loss_criterion = torch.nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    corrects ,total_loss,total_bce_loss,_size,bce_loss = 0,0,0,0,0\n",
    "    for q1, q2, label,a,b in tqdm.tqdm_notebook(train_dataloader, mininterval=1,\n",
    "                                  desc='Train Processing', leave=False):\n",
    "        label = label.type(torch.LongTensor)\n",
    "        q1 = Variable(q1)\n",
    "        q2 = Variable(q2)\n",
    "        label = Variable(label)\n",
    "        optimizer.zero_grad()\n",
    "        pred1,pred2 = model(q1, q2)\n",
    "        loss = criterion(pred1, label)\n",
    "        bce_loss = bce_loss_criterion(pred2,label.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "        total_bce_loss += bce_loss.data\n",
    "        corrects += (torch.max(pred1, 1)[1].view(label.size()).data == label.data).sum()\n",
    "        _size += train_dataloader.batch_size\n",
    "    return total_loss /_size , corrects ,(float(corrects) / _size) * 100, _size,total_bce_loss /_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    corrects ,total_loss,total_bce_loss,_size,bce_loss = 0,0,0,0,0\n",
    "    for q1, q2, label,_,_ in tqdm.tqdm_notebook(valid_dataloader, mininterval=1,\n",
    "                                  desc='validation Processing', leave=False):\n",
    "        label = label.type(torch.LongTensor)\n",
    "        q1 = Variable(q1)\n",
    "        q2 = Variable(q2)\n",
    "        label = Variable(label)\n",
    "        pred1,pred2 = model(q1, q2)\n",
    "        loss = criterion(pred1, label)\n",
    "        bce_loss = bce_loss_criterion(pred2,label.type(torch.FloatTensor))\n",
    "        total_loss += loss.data\n",
    "        total_bce_loss += bce_loss.data\n",
    "        corrects += (torch.max(pred1, 1)[1].view(label.size()).data == label.data).sum()\n",
    "        _size += valid_dataloader.batch_size\n",
    "    return total_loss /_size , corrects ,(float(corrects) / _size) * 100, _size,total_bce_loss /_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(filename):\n",
    "    state = {'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict(), 'valid_loss': valid_loss,\"valid_bce_loss\": valid_bce_loss,\n",
    "             'valid_accuracy':valid_accuracy}\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8103bc2ace3f4708b285432689e2369b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.py:79: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x_softmax = F.log_softmax(x)\n",
      "/home/shaurya/anaconda2/lib/python2.7/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "| start of epoch   1 | time: 260.82s | loss 0.911245 | accuracy 62.7097%(228203/363904) | bce_loss 0.784830\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0b1f9be91d4407ba69ccda00e216e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 0.00s | loss 0.6583 | accuracy 63.0513%(25503/40448 | bce_loss 0.667471\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b005bde9c354fe38e4a5bbb2a37f5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "| start of epoch   2 | time: 261.48s | loss 0.658763 | accuracy 63.0724%(229523/363904) | bce_loss 0.668443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32481ac9ec4c46e287f4c721a166679c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 0.00s | loss 0.6583 | accuracy 63.0513%(25503/40448 | bce_loss 0.667451\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11db084c681a4596ab2ea12107058b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Exiting from training early | cost time: 13.06min\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "validation_loss = []\n",
    "training_bce_loss = []\n",
    "validation_bce_loss = []\n",
    "train_accuracy = []\n",
    "valid_accuracy =[]\n",
    "best_acc = None\n",
    "total_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    print('-' * 90)\n",
    "    for epoch in range(1, NUM_EPOCH + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss, train_corrects, train_acc, train_size,train_bce_loss = train()\n",
    "        scheduler.step()\n",
    "        training_loss.append(train_loss * 1000.)\n",
    "        training_bce_loss.append(train_bce_loss * 1000.)\n",
    "        train_accuracy.append(train_acc/100.)\n",
    "\n",
    "        print('| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f} | accuracy {:.4f}%({}/{}) | bce_loss {:5.6f}'.format(\n",
    "            epoch, time.time() - epoch_start_time, train_loss, train_acc, train_corrects, train_size,train_bce_loss))\n",
    "\n",
    "        valid_loss, valid_corrects, valid_acc, valid_size,valid_bce_loss = evaluate()\n",
    "\n",
    "        validation_loss.append(valid_loss * 1000.)\n",
    "        validation_bce_loss.append(valid_loss * 1000.)\n",
    "        valid_accuracy.append(valid_acc / 100.)\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "        print('-' * 90)\n",
    "        print('| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{} | bce_loss {:5.6f}'.format(\n",
    "            epoch, time.time() - epoch_start_time, valid_loss, valid_acc, valid_corrects, valid_size,valid_bce_loss))\n",
    "        print('-' * 90)\n",
    "        if not best_acc or best_acc < valid_acc:\n",
    "            best_acc = valid_acc\n",
    "            save('../save/checkpoint_epoch_'+str(epoch)+'_valid_loss_'+str(valid_loss)\n",
    "              +'_valid_acc_'+str(valid_acc)+'_valid_bce_loss_'+str(valid_bce_loss)+'_'+'.pth.tar')\n",
    "except KeyboardInterrupt:\n",
    "    print(\"-\" * 90)\n",
    "    print(\"Exiting from training early | cost time: {:5.2f}min\".format(\n",
    "        (time.time() - total_start_time) / 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
